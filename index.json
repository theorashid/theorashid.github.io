[{"authors":["admin"],"categories":null,"content":"I am currently studying for a PhD in the Global Environmental Health group at the School of Public Health, Imperial College London under the supervision of Majid Ezzati, James Bennett, Seth Flaxman and Mireille Toledano.\nAs part of the Pathways to Equitable Healthy Cities collaboration, my research looks at small-area trends in mortality in London and England using both Bayesian parametric and nonparametric models. I am interested in how environmental and economic deprivation impact different subgroups of the population.\nI previously read theoretical physics, also at Imperial College, writing my thesis on the dynamics of hurricanes.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://theorashid.github.io/author/theo-rashid/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/theo-rashid/","section":"authors","summary":"I am currently studying for a PhD in the Global Environmental Health group at the School of Public Health, Imperial College London under the supervision of Majid Ezzati, James Bennett, Seth Flaxman and Mireille Toledano.","tags":null,"title":"Theo Rashid","type":"authors"},{"authors":["Theo Rashid"],"categories":["probabilistic programming","modelling","statistics","football"],"content":"\u0026ldquo;West Ham are playing Norwich later. What do you reckon the score will be?\u0026rdquo;\nOur gut might tell us which team will win. But how can we quantify this intuition? And what uncertainty do we attach to our belief in the result?\nThis sort of question is ideally suited to a Bayesian modelling framework. Here, we\u0026rsquo;ll build a model to predict future scorelines with uncertainty based on past results using Pyro – a \u0026ldquo;Deep Universal Probabilistic Programming\u0026rdquo; language – and make use of its PyTorch backend by tuning the model with stochastic variational inference (SVI).\nThe problem The aim is to train a model on the results of the first 33 rounds of a Premier League season. Then, use this model to predict the scorelines of the final games of the season.\nNo model is perfect, and this one is very basic. With data collected in modern football on everything from player movement to the atmospheric conditions inside the stadium, the potential complexity of the model is huge. We\u0026rsquo;ll stick to three factors: the attacking strength of each team; the defending strength of each team; and the home advantage.\nThe model This Bayesian multilevel model is (heavily) inspired by Baio and Blangiardo. For each game, $g$, the number of goals scored, $s$, by the home ($j=1$) or away ($j=2$) team follows a Poisson distribution $$ s_{gj} | \\theta_{gj} \\sim Poisson(\\theta_{gj}). $$\nThe (positive) scoring rates are made up of an overall offset, a home advantage and team-specific strengths, $$ \\log(\\theta_{g1}) = \\alpha + home + attack_{h(g)} - defend_{a(g)}, $$ $$ \\log(\\theta_{g2}) = \\alpha + attack_{a(g)} - defend_{h(g)}, $$\nwhere the nested indexes $h(g)$ and $a(g)$ identify the home and away teams. For each team, $t (= h(g), a(g))$, we model their attacking and defensive strength using normal distributions centred on zero with common standard deviations, $$ attack_{t} \\sim \\mathcal{N}(0, \\sigma_{att}^2),$$ $$ defend_{t} \\sim \\mathcal{N}(0, \\sigma_{def}^2).$$\nFinally the hyperpriors round off the Bayesian model, $$ home \\sim \\mathcal{N}(0, 1),$$ $$ \\sigma_{att} \\sim HalfStudentT(3, 0, 2.5),$$ $$ \\sigma_{def} \\sim HalfStudentT(3, 0, 2.5).$$\nThe model written using Pyro:\ndef model(home_id, away_id, score1_obs=None, score2_obs=None): # hyperpriors alpha = pyro.sample(\u0026quot;alpha\u0026quot;, dist.Normal(0.0, 1.0)) sd_att = pyro.sample(\u0026quot;sd_att\u0026quot;, dist.TransformedDistribution(dist.StudentT(3.0, 0.0, 2.5), FoldedTransform())) sd_def = pyro.sample(\u0026quot;sd_def\u0026quot;, dist.TransformedDistribution(dist.StudentT(3.0, 0.0, 2.5), FoldedTransform())) home = pyro.sample(\u0026quot;home\u0026quot;, dist.Normal(0.0, 1.0)) # home advantage nt = len(np.unique(home_id)) # team-specific model parameters with pyro.plate(\u0026quot;plate_teams\u0026quot;, nt): attack = pyro.sample(\u0026quot;attack\u0026quot;, dist.Normal(0, sd_att)) defend = pyro.sample(\u0026quot;defend\u0026quot;, dist.Normal(0, sd_def)) # likelihood theta1 = torch.exp(alpha + home + attack[home_id] - defend[away_id]) theta2 = torch.exp(alpha + attack[away_id] - defend[home_id]) with pyro.plate(\u0026quot;data\u0026quot;, len(home_id)): pyro.sample(\u0026quot;s1\u0026quot;, dist.Poisson(theta1), obs=score1_obs) pyro.sample(\u0026quot;s2\u0026quot;, dist.Poisson(theta2), obs=score2_obs)  Inference If we were tuning our model parameters using sampling methods, that would be it. Press play, let the sampler run, wait until you have enough samples\u0026hellip; done. But we\u0026rsquo;re going to use variational inference to optimise our parameters. For this, Pyro requires a guide.\nThe guide The idea behind variational inference is to approximate a complex distribution – our true posterior, $p(\\mathbf{z}|\\mathbf{x})$ – with a simpler one – the variational distribtion, $q(\\mathbf{z})$. In Pyro-speak, the variational distribution is called the guide.\nIf possible, let Pyro do the process for you with an AutoGuide. Designing a custom guide is by far the hardest part of using Pyro and it should be avoided.\nWe need to specify a guide that is flexible enough to closely describe the posterior. Often, we can simply micic the model prior, setting the parameters of each of the prior distributions as variational parameters, which we will learn. But you are free to customise the guide as you want, as long as the dimensionality of the model and guide are consistent.\nWhen writing a guide:\n Every pyro.sample statement that appears in the model must have a corresponding pyro.sample statement with the same name in the guide, with the expection of those with the obs keyword . The parameters that make up the pyro.sample distributions in the guide require their own pyro.param statements. These variational parameters are going to be trained during inference.  I\u0026rsquo;ve kept the guide below fairly simple with normal distributions where possible and log-normal distributions for the positive parameters. SVI is an approximate method; these simple distributions will mask some of the complexity in the posterior distribution, no matter how well the inference goes. You can construct a more sophisticated guide to improve its performance.\ndef guide(home_id, away_id, score1_obs=None, score2_obs=None): mu_locs = pyro.param(\u0026quot;mu_loc\u0026quot;, torch.tensor(0.0).expand(4)) mu_scales = pyro.param(\u0026quot;mu_scale\u0026quot;, torch.tensor(0.1).expand(4), constraint=constraints.positive) pyro.sample(\u0026quot;alpha\u0026quot;, dist.Normal(mu_locs[0], mu_scales[0])) pyro.sample(\u0026quot;sd_att\u0026quot;, dist.LogNormal(mu_locs[1], mu_scales[1])) pyro.sample(\u0026quot;sd_def\u0026quot;, dist.LogNormal(mu_locs[2], mu_scales[2])) pyro.sample(\u0026quot;home\u0026quot;, dist.Normal(mu_locs[3], mu_scales[3])) # home advantage nt = len(np.unique(home_id)) mu_team_locs = pyro.param(\u0026quot;mu_team_loc\u0026quot;, torch.tensor(0.0).expand(2, nt)) mu_team_scales = pyro.param(\u0026quot;mu_team_scale\u0026quot;, torch.tensor(0.1).expand(2, nt), constraint=constraints.positive) with pyro.plate(\u0026quot;plate_teams\u0026quot;, nt): pyro.sample(\u0026quot;attack\u0026quot;, dist.Normal(mu_team_locs[0], mu_team_scales[0])) pyro.sample(\u0026quot;defend\u0026quot;, dist.Normal(mu_team_locs[1], mu_team_scales[1]))  We can now train the model using SVI on the first 33 rounds of Premier League football matches. The training process aims to find the pyro.param values that get the guide as close as possible to the posterior.\nBelow are posterior estimates for the attack and defend parameters. As expected, Manchester City and Liverpool are the strongest teams.\n\nPrediction Here lies the beauty of a generative model. We can now feed any combination of teams into the trained model and simulate a game. (You can even play out nonsenical matches like Machester United against Manchester United.)\nThe model is Bayesian, so we can generate samples for a fixture – imaginary head-to-heads between the same two teams – and probabilistically determine each team\u0026rsquo;s chance of winning the match. We\u0026rsquo;ll input the fixture list of the final 5 rounds of matches in the predict dataframe and simulate 2000 games.\npredictive = Predictive(model=model, guide=guide, num_samples=2000, return_sites=[\u0026quot;s1\u0026quot;, \u0026quot;s2\u0026quot;]) predicted_score = predictive(home_id=predict[\u0026quot;Home_id\u0026quot;].values, away_id=predict[\u0026quot;Away_id\u0026quot;].values)  Taking an example from this fixture list – Chelsea hosting Norwich – we can see that Chelsea dominated the majority of the matches. We expect this as Chelsea have the home advantage and a stronger side. But, as the model is probabilistic, there are still many scenarios in which Norwich came out on top. Using the mean number of goals scored by each team across all simulations, we can compare the true final table and our model predictions.\n   Team Points GD Predicted Points Predicted GD     Liverpool FC 99 52 104 52   Manchester City FC 81 67 81 55   Manchester United FC 66 30 65 25   Chelsea FC 66 15 65 17   Leicester City FC 62 26 73 37   Tottenham Hotspur FC 59 14 56 9   Wolverhampton Wanderers FC 59 11 58 9   Arsenal FC 56 8 55 7   Sheffield United FC 54 0 52 0   Burnley FC 54 -7 50 -10   Southampton FC 52 -9 46 -15   Everton FC 49 -12 54 -6   Newcastle United FC 44 -20 46 -13   Crystal Palace FC 43 -19 47 -12   Brighton \u0026amp; Hove Albion FC 41 -15 39 -11   West Ham United FC 39 -13 39 -17   Aston Villa FC 35 -26 28 -30   AFC Bournemouth 34 -25 28 -32   Watford FC 34 -28 30 -26   Norwich City FC 21 -49 24 -39    The model performs well on the whole. There are exceptions such as Leicester, who had a poor finish to the season that did not reflect the training data. Leicester have been weak finishers in the recent past, so one way to improve the model would be to include data from previous seasons.\nFind the working model code here.\nThanks to @martinjankowiak on the Pyro forum for all the help making this run. Find the discussion here.\n","date":1632593575,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633889575,"objectID":"0ad3d493865ad73e9902e171bf4b8f28","permalink":"https://theorashid.github.io/post/pyro-pl-model/","publishdate":"2021-09-25T19:12:55+01:00","relpermalink":"/post/pyro-pl-model/","section":"post","summary":"Using Pyro and SVI to predict football results.","tags":[],"title":"Pyro: a guide to winning the Premier League","type":"post"},{"authors":["Theo Rashid","Toby Pepperrell"],"categories":null,"content":"","date":1612137600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1612137600,"objectID":"e4f2d1f04c6eddca2446137d8d2c20c6","permalink":"https://theorashid.github.io/publication/rashid-2021/","publishdate":"2021-04-20T20:51:42.930006Z","relpermalink":"/publication/rashid-2021/","section":"publication","summary":"","tags":["degrowth","covid-19"],"title":"Recentring our economy around wellbeing following the COVID-19 pandemic: A book review of The Case for Degrowth","type":"publication"},{"authors":["Toby Pepperrell","Florence Rodgers","Pranav Tandon","Kelly Sarsfield","Molly Pugh-Jones","Theo Rashid","Sarai Keestra"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"4f38f33c72a4f79938029d934fc83461","permalink":"https://theorashid.github.io/publication/pepperrell-2021/","publishdate":"2021-04-20T20:51:42.935071Z","relpermalink":"/publication/pepperrell-2021/","section":"publication","summary":"Coronavirus disease 2019 (COVID-19) mortality and morbidity have been shown to increase with deprivation and impact non-White ethnicities more severely. Despite the extra risk Black, Asian and Minority Ethnicity (BAME) groups face in the pandemic, our current medical research system seems to prioritise innovation aimed at people of European descent. We found significant difficulties in assessing baseline demographics in clinical trials for COVID-19 vaccines, displaying a lack of transparency in reporting. Further, we found that most of these trials take place in high-income countries, with only 25 of 219 trials (11.4%) taking place in lower middle- or low-income countries. Trials for the current best vaccine candidates (BNT162b2, ChadOx1, mRNA-173) recruited 80.0% White participants. Underrepresentation of BAME groups in medical research will perpetuate historical distrust in healthcare processes, and poses a risk of unknown differences in efficacy and safety of these vaccines by phenotype. Limiting trial demographics and settings will mean a lack of global applicability of the results of COVID-19 vaccine trials, which will slow progress towards ending the pandemic.","tags":["covid-19","trials"],"title":"Making a COVID-19 vaccine that works for everyone: ensuring equity and inclusivity in clinical trials","type":"publication"},{"authors":["Vasilis Kontis","James E Bennett","Theo Rashid","Robbie M Parks","Jonathan Pearson-Stuttard","Michel Guillot","Perviz Asaria","Bin Zhou","Marco Battaglini","Gianni Corsetti","Martin McKee","Mariachiara Di Cesare","Colin D Mathers","Majid Ezzati"],"categories":null,"content":"","date":1602633600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602633600,"objectID":"bba21ddfe8a6acb91d432e341606226b","permalink":"https://theorashid.github.io/publication/kontis-2020-a/","publishdate":"2020-10-17T11:25:55.101685Z","relpermalink":"/publication/kontis-2020-a/","section":"publication","summary":"The Coronavirus Disease 2019 (COVID-19) pandemic has changed many social, economic, environmental and healthcare determinants of health. We applied an ensemble of 16 Bayesian models to vital statistics data to estimate the all-cause mortality effect of the pandemic for 21 industrialized countries. From mid-February through May 2020, 206,000 (95% credible interval, 178,100–231,000) more people died in these countries than would have had the pandemic not occurred. The number of excess deaths, excess deaths per 100,000 people and relative increase in deaths were similar between men and women in most countries. England and Wales and Spain experienced the largest effect: ̃100 excess deaths per 100,000 people, equivalent to a 37% (30–44%) relative increase in England and Wales and 38% (31–45%) in Spain. Bulgaria, New Zealand, Slovakia, Australia, Czechia, Hungary, Poland, Norway, Denmark and Finland experienced mortality changes that ranged from possible small declines to increases of 5% or less in either sex. The heterogeneous mortality effects of the COVID-19 pandemic reflect differences in how well countries have managed the pandemic and the resilience and preparedness of the health and social care system.","tags":["coronavirus","bayesian","mortality","covid-19"],"title":"Magnitude, demographics and dynamics of the effect of the first wave of the COVID-19 pandemic on all-cause mortality in 21 industrialized countries","type":"publication"},{"authors":["Shuai Wang","Theo Rashid","Henry Throp","Ralf Toumi"],"categories":null,"content":"","date":1593561600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593561600,"objectID":"2c5f09aa6de9e50faa0ad5751dd3ff53","permalink":"https://theorashid.github.io/publication/wang-2020/","publishdate":"2020-10-17T11:25:55.112672Z","relpermalink":"/publication/wang-2020/","section":"publication","summary":"Abstract In this study a comprehensive picture of the changing intensity life cycle of major (Category 3 and higher) tropical cyclones (TCs) is presented. Over the past decades, the lifetime maximum intensity has increased, but there has also been a significant decrease in duration of time spent at intensities greater than Category 1. These compensating effects have maintained a stable global mean-accumulated cyclone energy of individual major TCs. The global mean duration of major TCs has shortened by about 1 day from 1982 to 2018. There has been both faster intensification (Categories 1 to 3) and weakening (Categories 3 to 1) by about 40%. The probabilities of rapid intensification and rapid weakening have both risen in the period 2000-2018 compared to 1982-1999. A statistically significant anticorrelation is found between the lifetime maximum intensity and the following duration of the final weakening. This suggests an element of self-regulation of TC life cycles.","tags":["intensity","life cycle","rapid intensification","rapid weakening","tropical cyclone"],"title":"A Shortening of the Life Cycle of Major Tropical Cyclones","type":"publication"},{"authors":["Vasilis Kontis","James E Bennett","Robbie M Parks","Theo Rashid","Jonathan Pearson-Stuttard","Perviz Asaria","Michel Guillot","Marta Blangiardo","Majid Ezzati"],"categories":null,"content":"","date":1589932800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589932800,"objectID":"cdd69066c8ccddf1155642fa4deaf469","permalink":"https://theorashid.github.io/publication/kontis-2020/","publishdate":"2020-06-02T11:51:15.124853Z","relpermalink":"/publication/kontis-2020/","section":"publication","summary":"Background: The COVID-19 pandemic affects mortality directly through infection as well as through changes in the social, environmental and healthcare determinants of health. The impacts on mortality are likely to vary, in both magnitude and timing, by age and sex. Our aim was to estimate the total mortality impacts of the pandemic, by sex, age group and week. Methods: We developed an ensemble of 16 Bayesian models that probabilistically estimate the weekly number of deaths that would be expected had the COVID-19 pandemic not occurred. The models account for seasonality of death rates, medium-long-term trends in death rates, the impact of temperature on death rates, association of death rates in each week on those in preceding week(s), and the impact of bank holidays. We used data from January 2010 through mid-February 2020 (i.e., week starting 15th February 2020) to estimate the parameters of each model, which was then used to predict the number of deaths for subsequent weeks as estimates of death rates if the pandemic had not occurred. We subtracted these estimates from the actual reported number of deaths to measure the total mortality impact of the pandemic. Results: In the week that began on 21st March, the same week that a national lockdown was put in place, there was a  92% probability that there were more deaths in men and women aged ≥ 45 years than would occur in the absence of the pandemic; the probability was 100% from the subsequent week. Taken over the entire period from mid-February to 8th May 2020, there were an estimated ∼ 49,200 (44,700-53,300) or 43% (37-48) more deaths than would be expected had the pandemic not taken place. 22,900 (19,300-26,100) of these deaths were in females (40% (32-48) higher than if there had not been a pandemic), and 26,300 (23,800-28,700) in males (46% (40-52) higher). The largest number of excess deaths occurred among women aged \u0026gt;85 years (12,400; 9,300-15,300), followed by men aged  85 years (9,600; 7,800-11,300) and 75-84 years (9,000; 7,500-10,300). The cause of death assigned to the majority (37,295) of these excess deaths was COVID-19. There was nonetheless a \u0026gt;99.99% probability that there has been an increase in deaths assigned to other causes in those aged ≥45 years. However, by the 8th of May, the all-cause excess mortality had become virtually equal to deaths assigned to COVID-19, and non-COVID excess deaths had diminished to close to zero, or possibly become negative, in all age-sex groups. Interpretation: The death toll of COVID-19 pandemic, in middle and older ages, is substantially larger than the number of deaths reported as a result of confirmed infection, and was visible in vital statistics when the national lockdown was put in place. When all-cause mortality is considered, the mortality impact of the pandemic on men and women is more similar than when comparing deaths assigned to COVID-19 as underlying cause of death.","tags":["coronavirus","bayesian","mortality","covid-19"],"title":"Age- and sex-specific total mortality impacts of the early weeks of the COVID-19 pandemic in England and Wales: Application of a Bayesian model ensemble to mortality statistics","type":"publication"}]